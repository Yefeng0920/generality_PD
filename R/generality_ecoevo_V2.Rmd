---
title: "Untitled"
output: html_document
date: '2024-05-30'
---


# Setup

```{r setup, echo = FALSE}
# Tidy
 # rm(list=ls())
 # graphics.off()
# Preparing workspace
knitr::opts_chunk$set(echo = TRUE, include = TRUE)
# Loading packages
pacman::p_load(knitr, # knit markdown
               readxl, 
               readr, 
               metafor, 
               dplyr, 
               tidyverse, 
               patchwork, # layout of plots
               cowplot, 
               ggpubr,
               gridExtra,
               gridGraphics, # Redraw Base Graphics Using 'grid' Graphics. `gridGraphics` is required to handle base-R plots.
               here,
               lme4,
               car, # logit transformation, car::logit()
               #boot, # Bootstrap Resampling
               ggthemes,
               wesanderson,
               raincloudplots,
               RColorBrewer,
               vcd,
               statpsych
               )
source(here("function","custom_function.R"))

# function to estimate typical sampling error variance
sigma2_v <- function(mod){
  sigma2_v <- sum(1 / mod$vi) * (mod$k - 1) /
    (sum(1 / mod$vi)^2 - sum((1 / mod$vi)^2))
  return(sigma2_v)
}

```


# Load data

```{r}
dat_list <- readRDS(here("Data", "dat_list.Rds"))
dat_list_rob <- readRDS(here("Data", "dat_list_rob.Rds"))

model_all <- readRDS(here("Data", "mod_fitted.Rds"))
model_all_rob <- readRDS(here("Data", "mod_rob_fitted.Rds"))
# add effect size types
names(model_all) <- sapply(dat_list, function(x) x$grouped_es[1])
names(model_all_rob) <- c(rep("lnRR", 7), rep("lnRR", 6), rep("SMD", 13), rep("SMD", 15), rep("Zr", 14))
model_all_PD <- c(model_all, model_all_rob)
```


# Default analysis

## PD
```{r}
#************************************************#
#----------------------PD----------------------#
#************************************************#

# compute PD
# function to calculate proportion above or below confidence interval threshold
calculate_threshold <- function(model) {
  # Calculate the mean and sd
  pred_dens_data <- pred_dist_data(model)
  
  # Check the sign of the model coefficient
  if (model$beta[1] > 0) {
    # Calculate proportion of effect sizes above lower confidence interval
    pred_dens_data$threshold <- propT_beyond(pred_dens_data, df = model$k.all - 1, threshold = model$ci.lb, tail = "above")
    pred_dens_data$group <- c("PD_b", "PD_w", "PD_t")
  } else {
    # Calculate proportion of effect sizes below upper confidence interval
    pred_dens_data$threshold <- propT_beyond(pred_dens_data, df = model$k.all - 1, threshold = model$ci.ub, tail = "below")
    pred_dens_data$group <- c("PD_b", "PD_w", "PD_t")
  }
  
  return(pred_dens_data)
}

# each model
threshold_list <- lapply(model_all_PD, calculate_threshold)

# dataframe
threshold_df <- bind_rows(threshold_list, .id = "model_index")
# reshape
threshold_df_wide <- pivot_wider(data = threshold_df, 
                                   names_from = group, 
                                   values_from = threshold)

PD_data <- threshold_df_wide %>% select(PD_t, PD_b, PD_w)
PD_data <- as.data.frame(lapply(PD_data, na.omit))
PD_data$es <- names(model_all_PD)

# model estimates
mod_stats <- data.frame(beta = sapply(model_all_PD, function(x) x$beta[1]),
                        beta.se = sapply(model_all_PD, function(x) x$se[1]),
                        beta.p = sapply(model_all_PD, function(x) x$pval[1]),
                        df = sapply(model_all_PD, function(x) x$ddf[1]),
                        CIL = sapply(model_all_PD, function(x) x$ci.lb[1]),
                        CIU = sapply(model_all_PD, function(x) x$ci.ub[1]),
                        sigma2_t = sapply(model_all_PD, function(x) sum(x$sigma2)),
                        sigma2_b = sapply(model_all_PD, function(x) x$sigma2[1]),
                        sigma2_w = sapply(model_all_PD, function(x) x$sigma2[2]),
                        QEp = sapply(model_all_PD, function(x) x$QEp),
                        I2_t = sapply(model_all_PD, function(x) i2_ml(x)[[1]]),
                        I2_b = sapply(model_all_PD, function(x) i2_ml(x)[[2]]),
                        I2_w = sapply(model_all_PD, function(x) i2_ml(x)[[3]]))




# typical sampling variance
mod_stats <- mod_stats %>% mutate(Vbar = sapply(model_all_PD, function(x) sigma2_v(x)))
# ratio
mod_stats <- mod_stats %>% mutate(sigma2_t_Vbar = sigma2_t / Vbar,
                                  sigma2_b_Vbar = sigma2_b / Vbar,
                                  sigma2_w_Vbar = sigma2_w / Vbar)


# combine
PD_data <- cbind(mod_stats, PD_data)
# CV
PD_data <- PD_data %>% mutate(CV_t = sqrt(sigma2_t) / abs(beta),
                              CV_b = sqrt(sigma2_b) / abs(beta),
                              CV_w = sqrt(sigma2_w) / abs(beta))
```

## PI
```{r}
#************************************************#
#----------------------PI----------------------#
#************************************************#
PD_data <- PD_data %>% 
  mutate(PIL_t = sapply(model_all_PD, function(x) x$beta[1]-qt(1-0.05/2,df=x$ddf[[1]])*sqrt(sum(x$sigma2)+x$se^2))) %>%
  mutate(PIU_t = sapply(model_all_PD, function(x) x$beta[1]+qt(1-0.05/2,df=x$ddf[[1]])*sqrt(sum(x$sigma2)+x$se^2))) %>%
  mutate(PIL_b = sapply(model_all_PD, function(x) x$beta[1]-qt(1-0.05/2,df=x$ddf[[1]])*sqrt(x$sigma2[1]+x$se^2))) %>%
  mutate(PIU_b = sapply(model_all_PD, function(x) x$beta[1]+qt(1-0.05/2,df=x$ddf[[1]])*sqrt(x$sigma2[1]+x$se^2))) %>% 
  mutate(PIL_w = sapply(model_all_PD, function(x) x$beta[1]-qt(1-0.05/2,df=x$ddf[[1]])*sqrt(x$sigma2[2]+x$se^2))) %>%
  mutate(PIU_w = sapply(model_all_PD, function(x) x$beta[1]+qt(1-0.05/2,df=x$ddf[[1]])*sqrt(x$sigma2[2]+x$se^2)))
```


# Scenario analysis
## Original
### PI
```{r}
## sig overall effect
length(which(PD_data$beta.p < 0.05)) # 321 / nrow(PD_data) - 63%
## or, equivalently, 
length(which(PD_data$CIL*PD_data$CIU > 0))

## sig total PI 
length(which(PD_data$PIL_t*PD_data$PIU_t > 0)) # 21 / 321 - 6%


# sig based on PI
PD_data <- PD_data %>% 
  mutate(sig_t = case_when(PD_data$PIL_t*PD_data$PIU_t > 0 ~ 'None-null',
          PD_data$PIL_t*PD_data$PIU_t < 0 ~ 'Null effect')) %>%
  mutate(sig_b = case_when(PD_data$PIL_b*PD_data$PIU_b > 0 ~ 'None-null',
          PD_data$PIL_b*PD_data$PIU_b < 0 ~ 'Null effect'))

# scenario where between-study level is lower than within-study level
PD_data_b <- filter(PD_data, sigma2_b < sigma2_w) 
## sig overall effect
length(which(PD_data_b$beta.p < 0.05)) # 162 / nrow(PD_data_b) - 67%
## sig PI total
length(which(PD_data_b$PIL_t*PD_data_b$PIU_t > 0)) # 13 / 162 - 8%
## sig PI between
length(which(PD_data_b$PIL_b*PD_data_b$PIU_b > 0)) # 59 / 162 - 36%


df_1x1 <- data_1x1(
  array_1 = PD_data_b$PD_t, 
  array_2 = PD_data_b$PD_b,
  jit_distance = .2,
  jit_seed = 321) 


paired_PD <- raincloud_1x1_repmes(
  data = df_1x1, 
  colors = brewer.pal(n = 8, name = "Dark2")[3:4],
  fills = brewer.pal(n = 8, name = "Dark2")[3:4],
  line_color = 'gray',
  line_alpha = .3,
  size = 1,
  alpha = .5,
  align_clouds = FALSE) +

scale_x_continuous(breaks=c(1,2), 
                   labels=c("Total", "Between-study")
                   ) +
  xlab(expression(paste("Dataset with"~italic(sigma)[b]^2~"<"~italic(sigma)[w]^2))) +
  ylab(expression(paste("PD"~">"~"95% lower bound"))) + 
  theme_bw() + 
  theme(axis.text = element_text(size = 8, color = "black"), 
        axis.title = element_text(size = 10, color = "black"),
        panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) 


png(filename = "figure/paired_PD.png", width = 10, height = 5, units = "in", type = "windows", res = 400)
paired_PD + paired_PD2 + plot_layout(ncol = 2, nrow = 1) + plot_annotation(tag_levels = "A") & theme(plot.tag = element_text(size = 20, face = "bold"))
dev.off()
```



#### Fig 2

```{r}
# scenario where between-study level is lower than within-study level
#PD_data_b <- filter(PD_data, sigma2_b < sigma2_w) 
PD_data_b <- filter(PD_data, beta.p < 0.05) 

# subgroup analysis
PD_data_b %>%
  group_by(es) %>%
  summarize(mean_PD = mean(PD_b, na.rm = TRUE))

# plot
df <- filter(PD_data_b, abs(beta) < 5) %>% arrange(beta) # potential outlier beta
#df <- filter(PD_data_b, PIL_b * PIU_b > 0)
df$id <- seq(1,nrow(df),by=1)

png(filename = "proposal.png", width = 5, height = 8, units = "in", type = "windows", res = 400)
 df %>% ggplot() +
   geom_hline(yintercept = 0, color = "black", linetype = "dotted") +
  #geom_ribbon(aes(x = id, ymin = PIL_t, ymax = PIU_t), fill="grey", alpha=0.4) +
  #geom_ribbon(aes(x = id, ymin = PIL_b, ymax = PIU_b, fill = sig_b), alpha=0.2) +
   geom_linerange(aes(x = id, ymin = PIL_b, ymax = PIU_b, color = sig_b), alpha=1) + 
  geom_point(aes(x = id, y = beta, color = sig_b), alpha=0.4) + 
  scale_color_manual(values = c("#3F6561", "#FCB462")) +
  theme_bw() + 
  theme(legend.position=c(1,0), 
        legend.justification=c(1,0),
        legend.direction='horizontal',
        axis.text = element_text(size = 11),
        axis.title = element_text(size = 11)) +
  theme(legend.background=element_rect(fill = alpha("white", 0))) + 
  labs(x = "Meta-analyes with different topics", y = "Predicted effect sizes", color = "")
dev.off()



p1 <- df %>% ggplot() +
   geom_hline(yintercept = 0, color = "blue", linetype = "dotted") +
   geom_linerange(aes(x = id, ymin = PIL_b, ymax = PIU_b, color = sig_b), alpha=1) + 
  geom_point(aes(x = id, y = beta, color = sig_b), alpha=0.4) + 
  #scale_color_manual(values = c("#3F6561", "#FCB462")) +
  scale_y_continuous(expand = c(0, 0)) +
  theme_bw() + 
  theme(
    legend.position = c(1, 0), 
    legend.justification = c(1, 0),
    legend.direction = 'horizontal',
    axis.text = element_text(size = 20, color = "black"),
    axis.title = element_text(size = 20),
    legend.title = element_text(size = 20), 
    legend.text = element_text(size = 20),
    legend.background = element_rect(fill = alpha("white", 0)),
    legend.key = element_rect(fill = alpha("white", 0)),
    axis.title.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  ) + 
  labs(x = "Meta-analyes with different topics", y = "Predicted effect sizes", color = "")

p2 <- ggplot(df, aes(x = id, y = PD_b/100)) +
  geom_segment(aes(x = id, xend = id, y = 50/100, yend = PD_b/100, color = sig_b)) +
  geom_point(aes(color = sig_b), alpha = 0.7, stroke = 2) +
  scale_size_continuous(range = c(1, 5)) + 
  #scale_y_continuous(limits = c(50/100, 100/100), breaks = seq(55/100,100/100,15/100), labels = scales::percent, expand = c(0, 0)) +
  scale_y_continuous(limits = c(0/100, 100/100), breaks = seq(0/100,100/100,25/100), labels = scales::percent, expand = c(0, 0)) +
  guides(color = "none") + 
  theme_bw() + 
  theme(legend.position=c(1,0), 
        legend.justification=c(1,0),
        legend.direction='horizontal',
        axis.text = element_text(size = 20, color = "black"),
        axis.title = element_text(size = 20),
        legend.title = element_text(size = 15),
        legend.text = element_text(size = 15)) +
  theme(legend.background=element_rect(fill = alpha("white", 0)),
        legend.key = element_rect(fill = alpha("white", 0))) + 
  labs(x = "Meta-analyes with different topics", y = "Study-level PD above meaningful thresholds", color = "", size = expression(italic(I)^2))

library(ggbreak)
p2 + scale_y_break(c(0.1, 0.50))

+ scale_y_continuous(breaks = c(0, 0.1))

p2 + scale_y_break(c(0.1, 0.5), scales = "fixed", ticklabels = c(15,20)) + scale_y_continuous(breaks = c(0,1))

p <- ggplot(d, aes(x, y)) + geom_col()
p+scale_y_break(c(1, 15), scales = "fixed",ticklabels = c(15,20)) + scale_y_continuous(breaks = c(0,1))


png(filename = "fig 2.png", width = 12, height = 16, units = "in", type = "windows", res = 600)
p1 / p2 + plot_layout(heights = c(1, 1)) + plot_annotation(tag_levels = 'A') & 
  theme(plot.tag = element_text(size = 20))
dev.off()

```

### PD

```{r}
# total
PD_data %>%
  summarize(Q1 = quantile(PD_t, probs = 0.25),
            medium = quantile(PD_t, probs = 0.50),
            Q3 = quantile(PD_t, probs = 0.75),
            mean = mean(PD_t, na.rm = TRUE))
```



## Decomposition
### PI
```{r}
## sig between PI 
length(which(PD_data$PIL_b*PD_data$PIU_b > 0)) # 71 / 321 - 22%
## sig effect size PI 
length(which(PD_data$PIL_w*PD_data$PIU_w > 0)) # 81 / 321 - 25%
```

### PD

```{r}
# between
PD_data %>%
  summarize(Q1 = quantile(PD_b, probs = 0.25),
            medium = quantile(PD_b, probs = 0.50),
            Q3 = quantile(PD_b, probs = 0.75),
            mean = mean(PD_b, na.rm = TRUE))

# effect size
PD_data %>%
  summarize(Q1 = quantile(PD_w, probs = 0.25),
            medium = quantile(PD_w, probs = 0.50),
            Q3 = quantile(PD_w, probs = 0.75),
            mean = mean(PD_w, na.rm = TRUE))
```


## Multiplier
### PD
```{r}
# compute PD with SE multiplier
# function to calculate proportion above or below confidence interval threshold

calculate_threshold <- function(model) {
  # Calculate the mean and sd
  pred_dens_data <- pred_dist_data(model)
  
  # Check the sign of the model coefficient
  if (model$beta[1] > 0) {
    # Calculate proportion of effect sizes above lower confidence interval
    pred_dens_data$threshold <- propT_beyond(pred_dens_data, df = model$k.all - 1, threshold = model$ci.lb, tail = "above")
    pred_dens_data$group <- c("PD_b", "PD_w", "PD_t")
  } else {
    # Calculate proportion of effect sizes below upper confidence interval
    pred_dens_data$threshold <- propT_beyond(pred_dens_data, df = model$k.all - 1, threshold = model$ci.ub, tail = "below")
    pred_dens_data$group <- c("PD_b", "PD_w", "PD_t")
  }
  
  return(pred_dens_data)
}

# Apply the function to each model in the list
threshold_list <- lapply(model_all_PD, calculate_threshold)

# Convert the list to a dataframe
threshold_df <- bind_rows(threshold_list, .id = "model_index")

threshold_df_wide <- pivot_wider(data = threshold_df, 
                                   names_from = group, 
                                   values_from = threshold)

PD_data <- threshold_df_wide %>% select(PD_t, PD_b, PD_w)
PD_data <- as.data.frame(lapply(PD_data, na.omit))
PD_data$es <- names(model_all_PD)

# extract model estimates
mod_stats <- data.frame(beta = sapply(model_all_PD, function(x) x$beta[1]),
                          beta.se = sapply(model_all_PD, function(x) x$se[1]),
                          beta.p = sapply(model_all_PD, function(x) x$pval[1]),
                          df = sapply(model_all_PD, function(x) x$ddf[1]),
                          CIL = sapply(model_all_PD, function(x) x$ci.lb[1]),
                          CIU = sapply(model_all_PD, function(x) x$ci.ub[1]),
                          sigma2_t = sapply(model_all_PD, function(x) sum(x$sigma2)),
                          sigma2_b = sapply(model_all_PD, function(x) x$sigma2[1]),
                          sigma2_w = sapply(model_all_PD, function(x) x$sigma2[2]),
                          QEp = sapply(model_all_PD, function(x) x$QEp))


# combine
PD_data <- cbind(mod_stats, PD_data)



## sig overall effect
length(which(PD_data$beta.p < 0.05)) # 321 / nrow(PD_data) - 63%
## or, equivalently, 
length(which(PD_data$CIL*PD_data$CIU > 0))

## sig total PI 
length(which(PD_data$PIL_t*PD_data$PIU_t > 0)) # 21 / 321 - 6%
## sig between PI 
length(which(PD_data$PIL_b*PD_data$PIU_b > 0)) # 71 / 321 - 22%
## sig effect size PI 
length(which(PD_data$PIL_w*PD_data$PIU_w > 0)) # 81 / 321 - 25%


PD_data <- PD_data %>% 
  mutate(sig_t = case_when(PD_data$PIL_t*PD_data$PIU_t > 0 ~ 'None-null',
          PD_data$PIL_t*PD_data$PIU_t < 0 ~ 'Null effect')) %>%
  mutate(sig_b = case_when(PD_data$PIL_b*PD_data$PIU_b > 0 ~ 'None-null',
          PD_data$PIL_b*PD_data$PIU_b < 0 ~ 'Null effect'))


# plot
# scenario where between-study level is lower than within-study level
PD_data_b <- filter(PD_data, sigma2_b < sigma2_w) 
## sig overall effect
length(which(PD_data_b$beta.p < 0.05)) # 162 / nrow(PD_data_b) - 67%
## sig PI total
length(which(PD_data_b$PIL_t*PD_data_b$PIU_t > 0)) # 13 / 162 - 8%
## sig PI between
length(which(PD_data_b$PIL_b*PD_data_b$PIU_b > 0)) # 59 / 162 - 36%


df_1x1 <- data_1x1(
  array_1 = PD_data_b$PD_t, 
  array_2 = PD_data_b$PD_b,
  jit_distance = .2,
  jit_seed = 321) 


paired_PD <- raincloud_1x1_repmes(
  data = df_1x1, 
  colors = brewer.pal(n = 8, name = "Dark2")[3:4],
  fills = brewer.pal(n = 8, name = "Dark2")[3:4],
  line_color = 'gray',
  line_alpha = .3,
  size = 1,
  alpha = .5,
  align_clouds = FALSE) +

scale_x_continuous(breaks=c(1,2), 
                   labels=c("Total", "Between-study")
                   ) +
  xlab(expression(paste("Dataset with"~italic(sigma)[b]^2~"<"~italic(sigma)[w]^2))) +
  ylab(expression(paste("PD"~">"~"95% lower bound"))) + 
  theme_bw() + 
  theme(axis.text = element_text(size = 8, color = "black"), 
        axis.title = element_text(size = 10, color = "black"),
        panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) 


png(filename = "figure/paired_PD.png", width = 10, height = 5, units = "in", type = "windows", res = 400)
paired_PD + paired_PD2 + plot_layout(ncol = 2, nrow = 1) + plot_annotation(tag_levels = "A") & theme(plot.tag = element_text(size = 20, face = "bold"))
dev.off()




# subgroup analysis
PD_data_b %>%
  group_by(es) %>%
  summarize(mean_PD = mean(PD_b, na.rm = TRUE))

# plot
df <- filter(PD_data_b, abs(beta) < 5) %>% arrange(beta)
df$id <- seq(1,nrow(df),by=1)

png(filename = "proposal.png", width = 5, height = 5, units = "in", type = "windows", res = 400)
  ggplot(df) +
  #geom_ribbon(aes(x = id, ymin = PIL_t, ymax = PIU_t), fill="grey", alpha=0.4) +
  #geom_ribbon(aes(x = id, ymin = PIL_b, ymax = PIU_b, fill = sig_b), alpha=0.2) +
   geom_linerange(aes(x = id, ymin = PIL_b, ymax = PIU_b, color = sig_b), alpha=0.4) + 
  geom_point(aes(x = id, y = beta, color = sig_b), alpha=0.4) + 
  scale_color_manual(values = c("blue", "red")) +
  theme_bw() + 
  theme(legend.position=c(0,1), 
        legend.justification=c(0,1),
        legend.direction='horizontal',
        axis.text = element_text(size = 11),
        axis.title = element_text(size = 11)) +
  theme(legend.background=element_rect(fill = alpha("white", 0))) + 
  labs(x = "Meta-analyes with different topics", y = "Effect sizes from future studies", color = "")
dev.off()

```

### PI

```{r}
# total
PD_data %>%
  summarize(Q1 = quantile(PD_t, probs = 0.25),
            medium = quantile(PD_t, probs = 0.50),
            Q3 = quantile(PD_t, probs = 0.75),
            mean = mean(PD_t, na.rm = TRUE))

# between
PD_data %>%
  summarize(Q1 = quantile(PD_b, probs = 0.25),
            medium = quantile(PD_b, probs = 0.50),
            Q3 = quantile(PD_b, probs = 0.75),
            mean = mean(PD_b, na.rm = TRUE))
```


# PD

```{r}
# Get the necessary data
pred_dens_data <- pred_dist_data(model_all[[1]])
	
# Calculate what proportion of effect sizes are beyond a biological threshold (in this case SMD = 0.2) for each of the two levels.
pred_dens_data$threshold <- propT_beyond(pred_dens_data, df = model_all[[1]]$k.all - 1, threshold = model_all[[1]]$ci.lb, tail = "above")
```


# ggbreak

```{r}
library(ggbreak)
set.seed(2019-01-19)
d <- data.frame(
  x = 1:20,
  y = c(rnorm(5) + 4, rnorm(5) + 20, rnorm(5) + 5, rnorm(5) + 22)
)

p <- ggplot(d, aes(x, y)) + geom_col()
p+scale_y_break(c(1, 15), scales = "fixed",ticklabels = c(15,20)) + scale_y_continuous(breaks = c(0,1))



p <- ggplot(d, aes(x, y)) + geom_col()
p + scale_y_cut(breaks=c(7, 18), which=c(1, 3), scales=c(3, 0.5))

p <- ggplot(economics, aes(x=date, y = unemploy, colour = uempmed)) +
     geom_line()
p + scale_wrap(n=4)

```



# Fig 1

Next, we illustrate how prediction intervals (PIs) combined with ‘prediction distributions’ (PDs) can be used to understand effect size heterogeneity and generality: 

```{r PD, echo = T, warning=FALSE}
############################################		
######## Simulate some meta-analytic data
############################################

set.seed(98)

# Parameters	
mu = 0.5  									   # Mean effect size. For example SMD. This is the mean contrast between two groups
tau = 0.1  									   # Between-study variance
obs = 0.6                                      # Within study varaince 
n = 50                                       # Number of studies
k = 100                                      # Number of effect sizes
vi = rgamma(k, shape = 0.5, scale = 0.1)	   # Effect size sampling variance. Sample from a gamma distribution

# Simulated effect size data
yi = mu + rep(rnorm(n, 0, sd = sqrt(tau)), k/n) + rnorm(k,0, obs) + rnorm(k, 0, sd = sqrt(vi))

# Create data
dat <- data.frame(yi = yi, vi = vi, study = rep(1:n, length = k), within = 1:k)

# Model
mod_sim <- rma.mv(yi, vi, random = list(~ 1 | study, ~1|within), data = dat, method = "REML")


# Get the necessary data
pred_dens_data <- pred_dist_data(mod_sim)[-2,]
pred_dens_data$group[1] <- "Between-study" 
pred_dens_data$group[2] <- "Total"
	
# Calculate what proportion of effect sizes are beyond a biological threshold (in this case SMD = 0.2) for each of the two levels.
pred_dens_data$threshold <- propT_beyond(pred_dens_data, df = mod_sim$k.all - 1, threshold = mod_sim$ci.lb, tail = "above")

mod_resultsdata <- mod_results(mod_sim, mod = "1", group = "study")$mod_table
# Orchardplot
sim_orchard <- orchard_plot(mod_sim, mod = "1", xlab = "Effect Size", group = "study", angle = 45, k.pos = "left") + 
	        ylim(-1.5, 2.5) +  
					geom_abline(intercept = mod_resultsdata$lowerPR, slope = 0, linetype = 2,  colour = "red") + 
					geom_abline(intercept = mod_resultsdata$upperPR, slope = 0, linetype = 2,  colour = "red") + 
     				theme(plot.margin = unit(c(0,0,0,0), 'lines'),
					  axis.title = element_text(size = 15, face = "bold"),
					  axis.text = element_text(size = 12),
					  axis.text.y = element_blank(),
					  axis.ticks.y = element_blank())


# Now create the density plot
	# t distribution
density_between <- data.frame(x = seq(-1.5,2.5,length.out = 1000)) %>% 
	  mutate(density = c(pred_Tdistri(x, df=mod_sim$k.all-1, m=pred_dens_data$mean[1], sd=pred_dens_data$sd[1]))) %>%
	  mutate(group = rep("Between-study", length(x)))
	density_total <- data.frame(x = seq(-1.5,2.5,length.out = 1000)) %>% 
	  mutate(density = c(pred_Tdistri(x, df=mod_sim$k.all-1, m=pred_dens_data$mean[2], sd=pred_dens_data$sd[2]))) %>%
	  mutate(group = rep("Total", length(x)))
	#density_dat <- rbind(density_between, density_total)
	#density_dat$group <- as.factor(density_dat$group)
	#density_dat$group <- factor(density_dat$group, levels = c("Total", "Between-study"))
	
	
dens_plot <- ggplot() +
	  geom_area(data = density_between, aes(x = x, y = density, fill = "Between-study"),alpha = 0.3) +
	  geom_area(data = density_total, aes(x = x, y = density, fill = "total"),alpha = 0.3) +
	  #scale_fill_manual(values = c("#D95F02", "#1B9E77"), labels = c(bquote("Total:"~paste(italic(sigma)[total]^2)~"= 0.37,"~paste(italic(I)[total]^2)~"= 100%,"~paste(italic(M)[total])~"= 0.46"), bquote("Between-study:"~paste(italic(sigma)[between]^2)~"= 0.08,"~paste(italic(I)[between]^2)~"= 20%,"~paste(italic(M)[between])~"= 0.21"))) + 
  scale_fill_manual(values = c("#D95F02", "#1B9E77")) +
	  stat_function(fun = pred_Tdistri_shaded, args = list(df = mod_sim$k.all - 1, m = pred_dens_data$mean[1], sd = pred_dens_data$sd[1], threshold = mod_sim$ci.lb),
	                geom = "area", fill = "#D95F02", alpha = 0.5) +
	  stat_function(fun = pred_Tdistri_shaded, args = list(df = mod_sim$k.all - 1, m = pred_dens_data$mean[2], sd = pred_dens_data$sd[2], threshold = mod_sim$ci.lb),
	                geom = "area", fill = "#1B9E77",  alpha = 0.5) +
	  theme_bw() + xlim(-1.5, 2.5) + labs(fill = "Stratum") +
	  geom_vline(xintercept = 0, linetype = 2,  colour = "black") +
	  geom_vline(xintercept = mod_resultsdata$lowerPR, linetype = 2,  colour = "red") + 
	  geom_vline(xintercept = mod_resultsdata$upperPR, linetype = 2,  colour = "red") + 
	  annotate("text", x = pred_dens_data$mean, y = c(0.8, 0.5), label = paste0(pred_dens_data$threshold, "%"), size = 5) + 
	  theme(legend.position= c(0, 1), 
	        legend.justification = c(0, 1), 
	        legend.background = element_blank(),
	        legend.text = element_text(size = 10),
	        legend.title = element_text(size = 15, face = "bold"),
	        axis.text = element_blank(),
	        axis.title = element_blank(),
	        axis.ticks = element_blank(),
	        plot.margin = unit(c(0,0,0,0), 'lines')) 
	
## normal distribution	
dens_plot2 <- ggplot(data = data.frame(x=c(-1.5,2.5)), aes(x = x, color = group, fill = group)) +
	        pred_distri(pred_dens_data) + 
	        scale_fill_manual(values = c("#D95F02", "#1B9E77"), labels = c(bquote("Total:"~paste(italic(sigma)[total]^2)~"= 0.37,"~paste(italic(I)[total]^2)~"= 100%,"~paste(italic(M)[total])~"= 0.46"), bquote("Between-study:"~paste(italic(sigma)[between]^2)~"= 0.08,"~paste(italic(I)[between]^2)~"= 20%,"~paste(italic(M)[between])~"= 0.21"))) + 
	        scale_color_manual(values = c("#D95F02", "#1B9E77"), labels = c(bquote("Total:"~paste(italic(sigma)[total]^2)~"= 0.37,"~paste(italic(I)[total]^2)~"= 100%,"~paste(italic(M)[total])~"= 0.46"), bquote("Between-study:"~paste(italic(sigma)[between]^2)~"= 0.08,"~paste(italic(I)[between]^2)~"= 20%,"~paste(italic(M)[between])~"= 0.21"))) +
	        stat_function(fun = pred_distri_shaded, args = list(m = pred_dens_data$mean[1], sd = pred_dens_data$sd[1], threshold = mod_sim$ci.lb),
	                geom = "area", fill = "#1B9E77", color = "#1B9E77", alpha = 0.6) +
	        stat_function(fun = pred_distri_shaded, args = list(m = pred_dens_data$mean[2], sd = pred_dens_data$sd[2], threshold = mod_sim$ci.lb),
	                geom = "area", fill = "#D95F02", color = "#D95F02", alpha = 0.6) +
	         #theme(legend.text.align = 0) +
					 theme_bw() + xlim(-1.5, 2.5) + labs(fill = "Stratum", color = "Stratum") +
					 geom_vline(xintercept = 0, linetype = 2,  colour = "black") +
					 geom_vline(xintercept = mod_resultsdata$lowerPR, linetype = 2,  colour = "red") + 
					  geom_vline(xintercept = mod_resultsdata$upperPR, linetype = 2,  colour = "red") + 
					 annotate("text", x = pred_dens_data$mean, y = c(0.8, 0.5), label = paste0(pred_dens_data$threshold, "%"), size = 5) + 
					 theme(legend.position= c(0, 1), 
			  				legend.justification = c(0, 1), 
			  				legend.background = element_blank(),
							legend.text = element_text(size = 10),
							legend.title = element_text(size = 15, face = "bold"),
			  				axis.text = element_blank(),
			  				axis.title = element_blank(),
			  				axis.ticks = element_blank(),
			  				plot.margin = unit(c(0,0,0,0), 'lines')) 

# Lets try plotting the orchard plot and the density plot together
ggsave("proposal2.png", width = 8, height = 8, dpi = 300)
ggarrange(dens_plot, sim_orchard, heights = c(2, 1),
          ncol = 1, nrow = 2, align = "v", common.legend = FALSE) 

```

